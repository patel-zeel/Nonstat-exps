{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.ProximalAdagradOptimizer is deprecated. Please use tf.compat.v1.train.ProximalAdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.ProximalAdagradOptimizer is deprecated. Please use tf.compat.v1.train.ProximalAdagradOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.ProximalGradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.ProximalGradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.ProximalGradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.ProximalGradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patel_zeel/anaconda3/lib/python3.7/site-packages/gpflow-1.5.1-py3.7.egg/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "from time import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import resource\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from gpflow.models.gpr import GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique timestamps are 7460\n",
      "unique timestamps after removing missing entry time-stamps are 2132\n"
     ]
    }
   ],
   "source": [
    "main_path = '~/Nonstat-exps/gp_extra/'\n",
    "df = pd.read_csv(main_path+'data/beijing_AQI.csv').rename(columns={'PM25_Concentration':'PM25','longitude':'long','latitude':'lat'})\n",
    "df = df.set_index('time').sort_index()\n",
    "print('unique timestamps are',len(df.index.unique()))\n",
    "useful_ts = []\n",
    "for ts in df.index.unique():\n",
    "  if(len(df.loc[ts])==36):\n",
    "    useful_ts.append(ts)\n",
    "df = df.loc[useful_ts]\n",
    "df['PM25'] = df['PM25'].astype(float)\n",
    "print('unique timestamps after removing missing entry time-stamps are',len(useful_ts))\n",
    "df.columns\n",
    "\n",
    "n_ts = 24 # Number of timestamps\n",
    "K = 4 #  Number of folds\n",
    "n_val = 2 # Number of validation stations\n",
    "\n",
    "splitter = KFold(K, shuffle=True, random_state=0)\n",
    "stations = np.sort(df['station_id'].unique())\n",
    "folds={i:{'train':None,'val':None,'test':None} for i in range(K)}\n",
    "for i, (train_val, test) in enumerate(splitter.split(stations)):\n",
    "    folds[i]['train'] = stations[train_val[:-n_val]]\n",
    "    folds[i]['val'] = stations[train_val[-n_val:]]\n",
    "    folds[i]['test'] = stations[test]\n",
    "    \n",
    "###########################\n",
    "# Data preperation\n",
    "###########################\n",
    "data = {i:{'train_Xy':None,'val_Xy':None,'test_Xy':None} for i in range(K)}\n",
    "for fold in range(K):\n",
    "    for part in ['train','val','test']:\n",
    "        data[fold][part+'_Xy'] = (df[df.station_id.isin(folds[fold][part])][['long', 'lat']], \n",
    "                                  df[df.station_id.isin(folds[fold][part])][['PM25']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold : Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_kriging/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 96 jobs on 32 CPUs\n",
      "2.675453821818034e-05 all fold complete\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for fold in range(K):\n",
    "    for ts in range(n_ts):\n",
    "        jobs.append('python scripts/process_kriging.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "init = time()\n",
    "maxa = 0\n",
    "while len(glob(path+'/*')) != len(jobs):\n",
    "    if maxa>10:\n",
    "        break\n",
    "    os.system(' | '.join(jobs))\n",
    "    print('round complete')\n",
    "    maxa+=1\n",
    "print((time()-init)/60, 'all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 rmse 26.490755411367843\n",
      "Fold 1 rmse 19.266591000794897\n",
      "Fold 2 rmse 21.581654903530094\n",
      "Fold 3 rmse 26.37639444792149\n",
      "Overall RMSE 23.63495115027866\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "tests = []\n",
    "for fold in range(K):\n",
    "    tmp_preds = []\n",
    "    tmp_tests = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "        preds.append(tmp['pred_y'].squeeze())\n",
    "        tests.append(tmp['test_y'].squeeze())\n",
    "        tmp_preds.append(tmp['pred_y'].squeeze())\n",
    "        tmp_tests.append(tmp['test_y'].squeeze())\n",
    "    print(\"Fold\",fold,'rmse',mean_squared_error(np.array(tmp_tests).flatten(), np.array(tmp_preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_rbf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 96 jobs on 32 CPUs\n",
      "5.7196617126464845e-05 all fold complete\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for fold in range(K):\n",
    "    for ts in range(n_ts):\n",
    "        jobs.append('python scripts/process_gp_rbf.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "init = time()\n",
    "maxa = 0\n",
    "while len(glob(path+'/*')) != len(jobs)*2:\n",
    "    if maxa>10:\n",
    "        break\n",
    "    os.system(' | '.join(jobs))\n",
    "    print('round complete')\n",
    "    maxa+=1\n",
    "print((time()-init)/60, 'all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 rmse 26.56725659802779\n",
      "Fold 1 rmse 18.633502800778835\n",
      "Fold 2 rmse 22.446714127157588\n",
      "Fold 3 rmse 25.487030306341303\n",
      "Overall RMSE 23.48653996821786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.00    37\n",
       "1.00      24\n",
       "0.10      19\n",
       "10.00     14\n",
       "0.01       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "tests = []\n",
    "hyp = []\n",
    "for fold in folds:\n",
    "    tmp_preds = []\n",
    "    tmp_tests = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "        hyp.append(tmp['best_hyperpara']['ls_init'])\n",
    "        preds.append(tmp['pred_y'].squeeze())\n",
    "        tests.append(tmp['test_y'].squeeze())\n",
    "        tmp_preds.append(tmp['pred_y'].squeeze())\n",
    "        tmp_tests.append(tmp['test_y'].squeeze())\n",
    "    print(\"Fold\",fold,'rmse',mean_squared_error(np.array(tmp_tests).flatten(), np.array(tmp_preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP-LLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_lls/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8959734996159872 seconds: a batch complete\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for fold in range(K):\n",
    "    for ts in range(n_ts):\n",
    "        jobs.append('python scripts/process_gp_lls.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "init = time()\n",
    "maxa = 0\n",
    "while len(glob(path+'/*')) != len(jobs)*2:\n",
    "    if maxa>10:\n",
    "        break\n",
    "#     os.system(' | '.join(jobs))\n",
    "    for b_id, batch in enumerate(np.array_split(jobs, 11)):\n",
    "        print(\"batch of\",len(batch),'started')\n",
    "        os.system(' | '.join(batch))\n",
    "        clear_output(wait=True)\n",
    "        print(b_id)\n",
    "        print((time()-init)/60, 'minutes: a batch complete')\n",
    "#     for j_id,job in enumerate(jobs):\n",
    "#         os.system(job)\n",
    "#         clear_output(wait=True)\n",
    "#         print(j_id)\n",
    "    print('round complete')\n",
    "    maxa+=1\n",
    "print((time()-init)/60, 'all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "tests = []\n",
    "hyp = []\n",
    "for fold in folds:\n",
    "    tmp_preds = []\n",
    "    tmp_tests = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "        hyp.append(tmp['best_hyperpara']['N'])\n",
    "        preds.append(tmp['pred_y'].squeeze())\n",
    "        tests.append(tmp['test_y'].squeeze())\n",
    "        tmp_preds.append(tmp['pred_y'].squeeze())\n",
    "        tmp_tests.append(tmp['test_y'].squeeze())\n",
    "    print(\"Fold\",fold,'rmse',mean_squared_error(np.array(tmp_tests).flatten(), np.array(tmp_preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in glob(path+'/*'):\n",
    "#     try:\n",
    "#         print(mean_squared_error(pd.read_pickle(file)['test_y'], pd.read_pickle(file)['pred_y'], squared=False))\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# N=3\n",
    "# model = GPR(scaler.fit_transform(data[fold]['train_Xy'][0].loc[ts].values), \n",
    "#                     data[fold]['train_Xy'][1].loc[ts].values,\n",
    "#                    LLS(2, scaler.fit_transform(data[fold]['train_Xy'][0].loc[ts].values), N, active_dims=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Kriging vs GP vs LLS NS-GP.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
