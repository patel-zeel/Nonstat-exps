{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "!pip -qq install psutil\n",
    "import psutil\n",
    "from time import time, sleep\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import resource\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "from NSGPy.NumPy import LLS\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from GPy.models import GPRegression as GPR\n",
    "from GPy.kern import Matern32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique timestamps are 7460\n",
      "unique timestamps after removing missing entry time-stamps are 2132\n"
     ]
    }
   ],
   "source": [
    "main_path = '~/Nonstat-exps/gp_extra/'\n",
    "df = pd.read_csv(main_path+'data/beijing_AQI.csv').rename(columns={'PM25_Concentration':'PM25','longitude':'long','latitude':'lat'})\n",
    "df = df.set_index('time').sort_index()\n",
    "print('unique timestamps are',len(df.index.unique()))\n",
    "useful_ts = []\n",
    "for ts in df.index.unique():\n",
    "  if(len(df.loc[ts])==36):\n",
    "    useful_ts.append(ts)\n",
    "df = df.loc[useful_ts]\n",
    "df['PM25'] = df['PM25'].astype(float)\n",
    "print('unique timestamps after removing missing entry time-stamps are',len(useful_ts))\n",
    "df.columns\n",
    "\n",
    "n_ts = len(useful_ts)\n",
    "K = 3 #  Number of folds\n",
    "n_val = 6 # Number of validation stations\n",
    "\n",
    "splitter = KFold(K, shuffle=True, random_state=0)\n",
    "stations = np.sort(df['station_id'].unique())\n",
    "folds={i:{'train':None,'val':None,'test':None} for i in range(K)}\n",
    "for i, (train_val, test) in enumerate(splitter.split(stations)):\n",
    "    folds[i]['train'] = stations[train_val[:-n_val]]\n",
    "    folds[i]['val'] = stations[train_val[-n_val:]]\n",
    "    folds[i]['test'] = stations[test]\n",
    "    \n",
    "###########################\n",
    "# Data preperation\n",
    "###########################\n",
    "data = {i:{'train_Xy':None,'val_Xy':None,'test_Xy':None} for i in range(K)}\n",
    "for fold in range(K):\n",
    "    for part in ['train','val','test']:\n",
    "        data[fold][part+'_Xy'] = (df[df.station_id.isin(folds[fold][part])][['long', 'lat']], \n",
    "                                  df[df.station_id.isin(folds[fold][part])][['PM25']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting average of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean fold rmse (mean) 24.169627837037883\n",
      "mean fold rmse (ind) 28.01549065975325\n",
      "mean fold rmse (mean) 21.408416061116977\n",
      "mean fold rmse (ind) 25.008867083189443\n",
      "mean fold rmse (mean) 21.70020189677074\n",
      "mean fold rmse (ind) 25.702693287190034\n",
      "mean overall rmse (mean) 22.426081931641868\n",
      "mean overall rmse (ind) 26.273812005535863\n"
     ]
    }
   ],
   "source": [
    "n_ts = 24*30\n",
    "preds = []\n",
    "tests = []\n",
    "n_fold_rmse = []\n",
    "for fold in range(K):\n",
    "    f_preds = []\n",
    "    f_tests = []\n",
    "    fold_rmse = []\n",
    "    for ts_n in range(n_ts):\n",
    "        ts = df.index.unique()[ts_n]\n",
    "        f_tests.append(data[fold]['test_Xy'][1].loc[ts].values)\n",
    "        f_preds.append(np.array([np.mean(data[fold]['train_Xy'][1].loc[ts].values)]*\\\n",
    "                                data[fold]['test_Xy'][1].loc[ts].values.shape[0]).reshape(-1,1))\n",
    "        preds.append(f_preds[-1])\n",
    "        tests.append(data[fold]['test_Xy'][1].loc[ts].values)\n",
    "        fold_rmse.append(mean_squared_error(f_tests[-1], f_preds[-1], squared=False))\n",
    "        n_fold_rmse.append(mean_squared_error(f_tests[-1], f_preds[-1], squared=False))\n",
    "    print('mean fold rmse (mean)', np.mean(fold_rmse))\n",
    "    print('mean fold rmse (ind)', mean_squared_error(np.concatenate(f_tests), np.concatenate(f_preds), squared=False))\n",
    "print('mean overall rmse (mean)', np.mean(n_fold_rmse))\n",
    "print('mean overall rmse (ind)', mean_squared_error(np.concatenate(tests), np.concatenate(preds), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df to save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_i = np.array(df.index.unique().tolist()*3).reshape(1,-1)\n",
    "n_time_id = np.array(list(range(len(df.index.unique())))*3).reshape(1,-1)\n",
    "n_fold_i = np.concatenate([np.ones(n_time_i.shape[1]//3)*0, \n",
    "                           np.ones(n_time_i.shape[1]//3)*1, \n",
    "                           np.ones(n_time_i.shape[1]//3)*2]).reshape(1,-1).astype(int)\n",
    "mult_i = np.concatenate([n_time_id, n_time_i, n_fold_i], axis=0)\n",
    "master_df = pd.DataFrame(index=pd.MultiIndex.from_arrays(mult_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP-LLS - matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_lls_self/'\n",
    "kernel = 'matern'\n",
    "n_ts = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if works\n",
    "# !python scripts/process_gp_lls_self.py 13 1 matern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end 2 of 2\n",
      "4.564747099081675 all fold complete\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "jobs = []\n",
    "for fold in range(K):\n",
    "    for ts in range(n_ts):\n",
    "        jobs.append('python scripts/process_gp_lls_self.py {0} {1} {2}'.format(ts, fold, kernel))\n",
    "\n",
    "print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "sleep(1)\n",
    "n_splits = len(jobs)//32\n",
    "for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "    print('start',b_id+1,'of',n_splits)\n",
    "    print('length of batch=',len(batch))\n",
    "    os.system(' | '.join(batch))\n",
    "    clear_output(wait=True)\n",
    "    print('end',b_id+1,'of',n_splits)\n",
    "print((time()-init)/60, 'all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean_rmse 26.86611876855044\n",
      "Fold 0 individual_rmse 31.51416245754586\n",
      "Fold 1 mean_rmse 21.72302760351303\n",
      "Fold 1 individual_rmse 24.81053715294914\n",
      "Fold 2 mean_rmse 25.08348017877968\n",
      "Fold 2 individual_rmse 28.925383849858157\n",
      "Overall RMSE (individual) 28.55044086104508\n",
      "Overall RMSE (mean of folds) 24.557542183614384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9    6\n",
       "4    6\n",
       "8    4\n",
       "3    4\n",
       "7    2\n",
       "6    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/raw_gp_lls_self/'+kernel+'/'\n",
    "name = 'lls_matern'\n",
    "master_df[name] = None\n",
    "preds = []\n",
    "tests = []\n",
    "mean_rmse_per_fold = []\n",
    "success = []\n",
    "n_fold_rmse = []\n",
    "for fold in folds:\n",
    "    hyp = []\n",
    "    fold_rmse = []\n",
    "    tmp_preds_y = []\n",
    "    tmp_models = []\n",
    "    tmp_tests_y = []\n",
    "    tmp_tests_x = []\n",
    "    tmp_train_Xy = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        try:\n",
    "            tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            hyp.append(tmp['best_hyperpara']['N'])\n",
    "            preds.append(tmp['pred_y'].squeeze())\n",
    "            tests.append(tmp['test_y'].squeeze())\n",
    "            tmp_models.append(tmp['best_model'])\n",
    "            tmp_train_Xy.append(tmp['train_Xy'])\n",
    "            tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "            tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "            tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "            success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name+'_model'] = tmp['best_model']\n",
    "        except:\n",
    "            pass\n",
    "    print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "    mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "    print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual check (Misc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAf0klEQVR4nO3df3SU5Z338fdXSE2glmBA+RF8gi5FtphCzLq62F0rlR+ilfYordWz7m5P6bbuU9rdUmHbWup2z9KyRwtn2z7L85QjPVa61CLqRksUdW1VakPAEJRfWpSEXykaWiHxAH6fP2YGJmGSzO+5557P65ycmbnue+65rkP45prvdd3XZe6OiIiEyzmFroCIiGSfgruISAgpuIuIhJCCu4hICCm4i4iE0OBCVwBgxIgRXlNTU+hqiIgUlc2bN//e3UcmOhaI4F5TU0NTU1OhqyEiUlTM7I2+jiktIyISQgruIiIhpOAuIhJCgci5i4ik48SJE7S1tdHd3V3oquRUeXk51dXVlJWVJf0eBXcRKVptbW2cd9551NTUYGaFrk5OuDtHjhyhra2N8ePHJ/0+pWWkby1r4b7JsKQy8tiyttA1Eumhu7ubqqqq0AZ2ADOjqqoq5W8n6rlLYi1r4bEvwYmuyOuj+yKvAWrnFa5eIr2EObDHpNNG9dwlsY33nAnsMSe6IuUiEngK7pLY0bbUykVKUGdnJz/84Q9Tft/1119PZ2dnDmp0hoK7JDasOrVykRLUV3A/efJkv+97/PHHqayszFW1AOXcpS/T7+6Zcwcoq4iUixSp9VvaWbZhJ/s7uxhTWcHCmROZO3Vs2tdbtGgRr732GlOmTKGsrIzy8nKGDx/Ojh072LVrF3PnzmXfvn10d3ezYMEC5s+fD5xZcuWdd95h9uzZXH311bzwwguMHTuWRx55hIqKiozbqp67JFY7D25cAcPGARZ5vHGFBlOlaK3f0s7iddto7+zCgfbOLhav28b6Le1pX3Pp0qVccsklbN26lWXLltHc3Mzy5cvZtWsXAKtWrWLz5s00NTWxYsUKjhw5ctY1du/ezZ133sn27duprKzkF7/4Rdr1iaeeu/Stdp6CuYTGsg076TpxqkdZ14lTLNuwM6Pee7wrrriix1z0FStW8PDDDwOwb98+du/eTVVVVY/3jB8/nilTpgBw+eWXs3fv3qzUZcCeu5mtMrPDZtaa4Ng/mZmb2YjoazOzFWa2x8xazKwuK7UUEcnQ/s6ulMrTMXTo0NPPn332WZ566ilefPFFXn75ZaZOnZpwrvq55557+vmgQYMGzNcnK5m0zP3ArN6FZjYOmAG8GVc8G5gQ/ZkP/CjzKoqIZG5MZeI8dl/lyTjvvPP44x//mPDY0aNHGT58OEOGDGHHjh1s2rQp7c9Jx4DB3d2fA95KcOg+4GuAx5XdBPzEIzYBlWY2Ois1FRHJwMKZE6koG9SjrKJsEAtnTkz7mlVVVUybNo3JkyezcOHCHsdmzZrFyZMnmTRpEosWLeLKK69M+3PSkVbO3cxuAtrd/eVed06NBfbFvW6Llh1IcI35RHr3XHTRRelUQ0QkabG8ejZnywA8+OCDCcvPPfdcnnjiiYTHYnn1ESNG0Np6JuP91a9+NaO6xEs5uJvZEOCfiaRk0ubuK4GVAPX19T7A6SIiGZs7dWzWBk+DLp2e+yXAeCDWa68Gms3sCqAdGBd3bnW0TERE8ijlee7uvs3dL3D3GnevIZJ6qXP3g8CjwF9HZ81cCRx197NSMiIiklvJTIVcA7wITDSzNjP7bD+nPw68DuwB/i/wxazUUkREUjJgWsbdbx3geE3ccwfuzLxaIiKSCS0/ICISQgruIiJpSnfJX4Dvf//7HD9+PMs1OkPBXUQkTUEO7lo4TERKR8vayG5iR9siexNMvzujxfHil/y97rrruOCCC1i7di3vvvsun/jEJ/j2t7/NsWPHmDdvHm1tbZw6dYpvfvObHDp0iP379/PRj36UESNG8Mwzz2SxkREK7iJSGnKwL/DSpUtpbW1l69atNDY28tBDD/HSSy/h7nz84x/nueeeo6OjgzFjxtDQ0BD52KNHGTZsGPfeey/PPPMMI0aMyEbrzqK0jIiUhhzvC9zY2EhjYyNTp06lrq6OHTt2sHv3bi677DKefPJJ7rrrLn71q18xbNiwrHzeQNRzF5HSkON9gd2dxYsX8/nPf/6sY83NzTz++ON84xvfYPr06dx9d+53NFPPXURKQw72BY5f8nfmzJmsWrWKd955B4D29nYOHz7M/v37GTJkCLfffjsLFy6kubn5rPfmgnruIlIacrAvcPySv7Nnz+Yzn/kMV111FQDvf//7eeCBB9izZw8LFy7knHPOoaysjB/9KLLNxfz585k1axZjxozJyYCqRW4qLaz6+npvamoqdDVEpMi8+uqrTJo0Kfk3ZHm2TD4laquZbXb3+kTnq+cuIqWjhPYFVs5dRCSEFNxFREJIwV1EJIQU3EVEQkjBXUQkhBTcRUQC4Nlnn+WGG27I2vUU3EVEcujUqVMF+VwFdxEpGQ2vNzDjoRnUrq5lxkMzaHi9IaPr7d27l0svvZTbbruNSZMmcfPNN3P8+HFqamq46667qKur4+c//zmNjY1cddVV1NXVccstt5xeouCXv/wll156KXV1daxbty4bTTwtmQ2yV5nZYTNrjSv7FzNrMbOtZtZoZmOi5WZmK8xsT/R4XVZrW4LWb2ln2tKnGb+ogWlLn2b9lvZCV0mkKDW83sCSF5Zw4NgBHOfAsQMseWFJxgF+586dfPGLX+TVV1/lAx/4wOnNO6qqqmhubuZjH/sY3/nOd3jqqadobm6mvr6ee++9l+7ubj73uc/x2GOPsXnzZg4ePJiNZp6WTM/9fmBWr7Jl7l7r7lOA/wZiizPMBiZEf+YDP8pSPUvS+i3tLF63jfbOLhxo7+xi8bptCvAiaVjevJzuU909yrpPdbO8eXlG1x03bhzTpk0D4Pbbb+fXv/41AJ/61KcA2LRpE6+88grTpk1jypQprF69mjfeeIMdO3Ywfvx4JkyYgJlx++23Z1SP3gZcfsDdnzOzml5lf4h7ORSILVBzE/ATjyxYs8nMKs1stLsfyFJ9S8qyDTvpOtEzX9d14hTLNuxk7tSxBaqVSHE6eCxxz7iv8mSZWcLXQ4cOBSJLAV933XWsWbOmx3lbt27N6HMHknbO3cz+1cz2Abdxpuc+FtgXd1pbtCzR++ebWZOZNXV0dKRbjVDb39mVUrmI9G3U0FEplSfrzTff5MUXXwTgwQcf5Oqrr+5x/Morr+T5559nz549ABw7doxdu3Zx6aWXsnfvXl577TWAs4J/ptIO7u7+dXcfB/wU+Ic03r/S3evdvX7kyJHpViPUxlRWpFQuIn1bULeA8kHlPcrKB5WzoG5BRtedOHEiP/jBD5g0aRJvv/02X/jCF3ocHzlyJPfffz+33nortbW1XHXVVezYsYPy8nJWrlzJnDlzqKur44ILLsioHr1lY1XInwKPA98C2oFxcceqo2WShoUzJ7J43bYeqZmKskEsnDmxgLWSvCviZWqDZM7Fc4BI7v3gsYOMGjqKBXULTpena/DgwTzwwAM9yvbu3dvj9bXXXstvf/vbs947a9YsduzYkdHn91mvdN5kZhPcfXf05U1ArHaPAv9gZj8D/hw4qnx7+mJ59WUbdrK/s4sxlRUsnDlR+fZSkoNNnUvZnIvnZBzMi8WAwd3M1gDXACPMrI1ID/16M5sIvAe8Afx99PTHgeuBPcBx4G9zUOeSMnfqWAXzUtbfps4K7gVXU1NDa2vrwCcWQDKzZW5NUPzjPs514M5MK1Xy9DVcYnK8qXMYuPtZM1bCJp0d83SHatDEvoYf3Qf4ma/hLWsLXTMphBxs6hwm5eXlHDlyJK3gVyzcnSNHjlBeXj7wyXG0zV7Q6Gu4xMvBps5hUl1dTVtbG2GfTl1eXk51dWp/0BXcg0ZfwyVe7A+60nQJlZWVMX78+EJXI5AU3INmWHU0JZOgXEpTCW3qLNmjnHvQTL878rU7nr6Gi0iKFNyDpnYe3LgCho0DLPJ44wr13EQkJUrLBJG+hotIhhTchfVb2nUXrEjIKLiXuNia8bH1a2JrxgMK8CJFTDn3EtffmvEiUrwU3Euc1owXCScF9xKnNeNFwknBvcQtnDmRirJBPcq0ZrxI8dOAaonTmvEi4aTgLlozXiSElJYREQkhBXcRkRBScBcRCaEBg7uZrTKzw2bWGle2zMx2mFmLmT1sZpVxxxab2R4z22lmM3NVcRER6VsyPff7gVm9yp4EJrt7LbALWAxgZn8KfBr4UPQ9PzSzQYiISF4NGNzd/TngrV5lje5+MvpyExDbSeIm4Gfu/q67/w7YA1yRxfqKiEgSspFz/zvgiejzsUD8NkJt0bKzmNl8M2sys6aw738oIpJvGQV3M/s6cBL4aarvdfeV7l7v7vUjR47MpBoiItJL2jcxmdnfADcA093do8XtwLi406qjZSIikkdpBXczmwV8Dfgrdz8ed+hR4EEzuxcYA0wAXsq4liI5EPRNSoJePwm2AYO7ma0BrgFGmFkb8C0is2POBZ40M4BN7v737r7dzNYCrxBJ19zp7qcSX1mkcIK+SUnQ6yfBZ2cyKoVTX1/vTU1Nha6GlJBpS5+mPcGa9WMrK3h+0bUFqFFPQa+fBIOZbXb3+kTHtHCYZF0xpBOCvklJ0OsnwaflBySrYumE9s4unDPphPVbgjWuHvRNSoJePwk+BXfJqmLZkzXom5QEvX4SfErLSFYVSzoh6JuUBL1+EnwK7pJVYyorEg4EBjGdEPRNSoJePwk2pWWCpmUt3DcZllRGHlvWFrpGKVE6QSQY1HMPkpa18NiX4ES053t0X+Q1QO28wtUrBUoniASD5rkHyX2TIwG9t2Hj4CutZ5eLSEnrb5670jJBcrQttfKwKPJUlEgQKbgHybDq1MrDIJaKOroP8DOpKAV4kYwouAfJ9LuhrNeskrKKSHlYbbznzBhDzImuSLmIpE3BPUhq58GNKyI5dizyeOOKohlMTUuppqJEckyzZYKmdl64g3lvw6r7GEQOcSpKJA/Uc5esW7+lnWlLn2b8ogamLX26/3VlSjEVJZIHCu7Sp4bXG5jx0AxqV9cy46EZNLzeMOB7Ul44rBRTUSJ5oLSMJNTwegNLXlhC96luAA4cO8CSF5YAMOfiOX2+r7+Fw/q8kanUUlEieaCeuyS0vHn56cAe032qm+XNy/t9X8YLh2nOu0hWKLhLQgePHUypPCajdcg1510kaxTc8yidHHahjBo6KqXymIwWDtOcd5GsGTC4m9kqMztsZq1xZbeY2XYze8/M6nudv9jM9pjZTjObmYtKF6NYDvvAsQM4fjqHHdQAv6BuAeWDynuUlQ8qZ0Hdgn7fN3fqWP7tk5cxtrICI7Ln57998rLkFg7TnHeRrElmQPV+4D+An8SVtQKfBP4z/kQz+1Pg08CHgDHAU2b2QXfvOcJWgvrLYccPUDa83sDy5uUcPHaQUUNHsaBuQb8DmLkS+8x06pL2OuSa8y6SNQMGd3d/zsxqepW9CmBmvU+/CfiZu78L/M7M9gBXAC9mo7LFLJkcdrozVHJlzsVz8vu50+/uueQxaM67SJqynXMfC8R3vdqiZWcxs/lm1mRmTR0dHVmuRmH0l1NPJoed7gyVbErpBqRsiJ8ds/Ee+PBnNOddJAsKNs/d3VcCKyGynnuh6pEtA/W6F9Qt6HEczs5hpztDJVtiNyDF5qnHbkACcrPZRqLNSV5+UAFdJAuy3XNvB8bFva6OloXeQL3uORfPYclfLGH00NEYxuiho1nyF0t6pD3SnaGSLf3dgJSslHr+G++h4X3GjOox1NaMY0b1GL5z3rnMaLqnKGYUiQRZtnvujwIPmtm9RAZUJwAvZfkzAimZXvdAOexkeve5lOkNSKn2/BtOvsWSEefTfU6kj3GgbDD/9YHzwAziZhRBYcYcRIpZMlMh1xAZEJ1oZm1m9lkz+4SZtQFXAQ1mtgHA3bcDa4FXgF8Cd5bKTJls9LqT6d3nUkY3IJF6z3951ZnAflqvQfq+xhyK6Z4BkUIYMLi7+63uPtrdy9y92t1/7O4PR5+f6+4XuvvMuPP/1d0vcfeJ7v5EbqsfHOnOC+8tlp8fNXQUB48dZHnz8rwFroxuQCL1nv/BQWfNtkp8Xq9vRcV2z0Cm9IdM0qE7VLMkW73uQgaujG5AIvWe/6iho5O6bu9vP0GYVZQvpfaHTLLH3As/UaW+vt6bmpoKXY1AmPHQDA4cO3BW+eiho2m8ubEANUpe75w7RHr+ff2BaHi9gUW/WtTvNcsHlZ/1R7J2dS3O2b+3htFyR0sGLQieYv59kNwzs83uXp/omHruAVPo6ZCZSLXnP9C3mr6+/fQ5jnGyMn/z8/OkmH8fpLC0nnvAjBo6KmFPLdmB2UIvX5Dq0gOjh45OuWeaaFaRv1dG16EZPTYIidWnmGX6+yClSz33gMlkYLYY87PptLf3+IadHE73gU9y8g9TT5+T6vz8oMrWQL2UnqLtua/f0s6yDTvZ39nFmMoKFs6cWPS9NMhswa5kFycLknTbG3/PwPhFDQky8ClsEBJgmfw+SGkrygHVVAfuSkUpDTTGm7b0adoTBPKxlRU8v+jaAtRIJD9CN6Cajdvkc6LAW8QVevmCQsl0fr5IGBVlcM94n85cCMAWcaWan810fr5IGBVlzn1MZUXCr+HJ3iafE/1tEZenFQ5LOT+b9gYhIiFVlMF94cyJCXPuBf0aHpAt4vK+wYakLayTAiQYijK4x/4DBOo/hraIkxTkfe18CZxc35NSlMEdAvg1XFvESQr6mxQQqN9ryYl8bKlZtME9cGJ59Y33RFIxw6ojgT0+396ytv/jIZVK+qFUUhWBnBQgeZOPe1IU3LOpdl7fwTrRlnKPfenM+0IqlfRDKaUqAjkpQPImH2sGFeVUyKLU32yaEEvlnoTA3r+QA5qbX9rycU+Kgnu+BGQ2Tb6lkn4opVSF5uaXtnzck6K0TL6U6GyaVNIPpZaqCNykAMmbfNyTksweqqvM7LCZtcaVnW9mT5rZ7ujj8Gi5mdkKM9tjZi1mVpe1mha76XdHZs/EK4HZNMmkH9ZvaT+9PkyijfeOvXsyNOuzi8TMuXgOjTc30nJHC403N2b9/pRk0jL3A7N6lS0CNrr7BGBj9DXAbGBC9Gc+8KPsVDMEaufBjStg2DjAIo83rgj1YCoMnH6IDaLGeuyJlrHr7DrB4nXbFOBFUpDUqpBmVgP8t7tPjr7eCVzj7gfMbDTwrLtPNLP/jD5f0/u8/q6vbfZKV18rOiaiVR5FesrFqpAXxgXsg8CF0edjgfjEclu0LFGl5ptZk5k1dXR0pFkNKXapDJaGcWBVJFcyni3jka5/yovCu/tKd6939/qRI0dmWg0pUqkMloZ1YFUkF9IN7oei6Riij4ej5e3AuLjzqqNlIgklGnAtG2SUndNzaFVzwEVSk25wfxS4I/r8DuCRuPK/js6auRI4OlC+XUpbogHXZTd/mGW3fFhzwEUyMOCAqpmtAa4BRgCHgG8B64G1wEXAG8A8d3/LzAz4DyKza44Df+vuA46UakBVRCR1/Q2oDngTk7vf2seh6QnOdeDO1KonIiLZpuUHpDgVeL9akaDT8gNSfEp0hU2RVKjnLsWnRFfYFEmFgrsUnxJdYVMkFQruUnz6Wkkz5CtsiqRCwV2KT4musCmSCgV3KT4lusKmSCo0W0aKU3/71YqIgnvotKyNzBo52hbJQU+/u+SD4Pot7SzbsJP9nV2Mqaxg4cyJWspAQk/BPUw0//sssc1AYhtvt3d2sXjdNgAFeAk15dzDRPO/z7Jsw87TgT2m68Qplm3YWaAaieSHgnuYaP73Wfra4EMbf0jYKbiHieZ/n6WvDT608YeEnYJ7mGj+91kSbQaijT+kFGhANUxig6aaLXNabNBUs2Wk1Ay4WUc+aLMOEZHU9bdZh9IyIiIhpOAuIhJCCu4iIiGUUXA3swVm1mpm283sy9Gy883sSTPbHX0cnp2qikixWL+lnWlLn2b8ogamLX2a9VvaC12lkpN2cDezycDngCuADwM3mNmfAIuAje4+AdgYfS0iJSK25EN7ZxfOmSUfFODzK5Oe+yTgN+5+3N1PAv8DfBK4CVgdPWc1MDezKopIMdGSD8GQSXBvBT5iZlVmNgS4HhgHXOjuB6LnHAQuTPRmM5tvZk1m1tTR0ZFBNUQkSLTkQzCkHdzd/VXgu0Aj8EtgK3Cq1zkOJJxI7+4r3b3e3etHjhyZbjVEJGC05EMwZDSg6u4/dvfL3f0vgbeBXcAhMxsNEH08nHk1JZ4GqyTItORDMGS0/ICZXeDuh83sIiL59iuB8cAdwNLo4yMZ11JO0/rkEnRa8iEYMlp+wMx+BVQBJ4B/dPeNZlYFrAUuAt4A5rn7W/1dR8sPJG/a0qdpT5C7HFtZwfOLri1AjUSkUPpbfiCjnru7fyRB2RFgeibXlb5psEpEkqE7VIuMBqtEJBkK7kVGg1Uikgyt515kNFglIslQcC9Cc6eOVTAXkX4pLSMiEkIK7iIiIaTgLiISQgruIiIhpOAuIhJCCu4iIiGk4C4iEkIK7iIiIaTgLiISQgruIiIhpOAuIhJCCu4iIiGk4C4iEkIK7iIiIZRRcDezr5jZdjNrNbM1ZlZuZuPN7DdmtsfM/svM3petyoqISHLSDu5mNhb4ElDv7pOBQcCnge8C97n7nwBvA5/NRkVFRCR5maZlBgMVZjYYGAIcAK4FHooeXw3MzfAzREQkRWkHd3dvB/4deJNIUD8KbAY63f1k9LQ2IOGWQWY238yazKypo6Mj3WqIiEgCmaRlhgM3AeOBMcBQYFay73f3le5e7+71I0eOTLcaIiKSQCZpmY8Bv3P3Dnc/AawDpgGV0TQNQDXQnmEdRUQkRZkE9zeBK81siJkZMB14BXgGuDl6zh3AI5lVUUREUpVJzv03RAZOm4Ft0WutBO4C/tHM9gBVwI+zUE8REUnB4IFP6Zu7fwv4Vq/i14ErMrmuiIhkRneoioiEkIK7iEgIKbiLiISQgruISAgpuIuIhJCCu4hICCm4i4iEkIK7iEgIKbiLiISQgruISAgpuIuIhJCCu4hICCm4i4iEkIK7iEgIKbiLiISQgruISAgpuIuIFELLWrhvMiypjDy2rM3q5TPaiUlERNLQshYe+xKc6Iq8Prov8hqgdl5WPkI9dxGRfNt4z5nAHnOiK1KeJWkHdzObaGZb437+YGZfNrPzzexJM9sdfRyetdqKiITB0bbUytOQdnB3953uPsXdpwCXA8eBh4FFwEZ3nwBsjL4WEZGYYdWplachW2mZ6cBr7v4GcBOwOlq+Gpibpc8QEQmH6XdDWUXPsrKKSHmWZCu4fxpYE31+obsfiD4/CFyY6A1mNt/MmsysqaOjI0vVEBEpArXz4MYVMGwcYJHHG1dkbTAVwNw9swuYvQ/YD3zI3Q+ZWae7V8Ydf9vd+82719fXe1NTU0b1EBEpNWa22d3rEx3LRs99NtDs7oeirw+Z2ejoB48GDmfhM0REJAXZCO63ciYlA/AocEf0+R3AI1n4DBERSUFGwd3MhgLXAeviipcC15nZbuBj0dciIpJHGd2h6u7HgKpeZUeIzJ4REZEC0R2qIiIhlPFsmaxUwqwDeCNHlx8B/D5H1y4ktau4qF3FpVja9b/cfWSiA4EI7rlkZk19TRUqZmpXcVG7iksY2qW0jIhICCm4i4iEUCkE95WFrkCOqF3FRe0qLkXfrtDn3EVESlEp9NxFREqOgruISAgVVXA3s1VmdtjMWuPKbjGz7Wb2npnV9zq/1sxejB7fZmblCa5Z8J2jctSuZWa2w8xazOxhM6vsfU6u5aJdcef+k5m5mY3IZRv6+OyctMvM/nf032y7mX0v1+1I8Pm5+D2cYmaboru1NZnZFfloS686JN0uM7ut1w5z75nZlATXLHjcGJC7F80P8JdAHdAaVzYJmAg8C9THlQ8GWoAPR19XAYMSXPN7wKLo80XAd0PSrhnA4Ojz74alXdFj44ANRG58GxGGdgEfBZ4Czo2+viAk7WoEZkefXw88G+R29XrfZUQ2IUp0rOBxY6Cfouq5u/tzwFu9yl51950JTp8BtLj7y9Hzjrj7qQTnFXznqFy0y90b3f1k9OUmIHv7dyUpR/9eAPcBXwMKMhsgR+36ArDU3d+Nnpf3pbJz1C4HPhB9PozI3g95lWK74t0K/KyPYwWPGwMpquCeog8CbmYbzKzZzL7Wx3lJ7RwVIMm2K97fAU/kuF6ZSqpdZnYT0B4LKkUg2X+vDwIfMbPfmNn/mNmf5bGO6Ui2XV8GlpnZPuDfgcV5q2HmPkXP5czjBT5uZLQqZMANBq4G/ozI5t0bLbJryca+3uDubmZBnxuaUrvM7OvASeCn+atiWgZsl5kNAf6ZSK+xWCT77zUYOB+4MnruWjO72KPf+wMo2XZ9AfiKu//CzOYBPyayFHigmdmfA8fdvXWgc4MaN8Lcc28DnnP337v7ceBxInm33opt56hk24WZ/Q1wA3BbgINETDLtugQYD7xsZnuJpJqazWxUXmuammT/vdqAdR7xEvAekcWrgirZdt3Bmf0efg7kfUA1TfH7QicS+LgR5uC+AbjMzIaY2WDgr4BXEpxXbDtHJdUuM5tFJC/98eh/vqAbsF3uvs3dL3D3GnevIRJg6tz9YP6rm7Rkfw/XExlUxcw+CLyPYK9KmGy79kePAVwL7M5T/dJmZucA8+g73w7FEDcKPaKbyg+Rv6QHgBNE/mN/FvhE9Pm7wCFgQ9z5twPbgVbge3Hl/4/oCDmRUf6NRH7pngLOD0m79gD7gK3Rn/8Thnb1uv5eCjNbJhf/Xu8DHoie0wxcG5J2XQ1sBl4GfgNcXgTtugbYlOA6gYobA/1o+QERkRAKc1pGRKRkKbiLiISQgruISAgpuIuIhJCCu4hICCm4i4iEkIK7iEgI/X/vXxLHDW0aNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "N = 0\n",
    "dim = 0\n",
    "plt.plot()\n",
    "plt.scatter(tmp_train_Xy[N][0][:,dim], tmp_train_Xy[N][1],label='train')\n",
    "plt.scatter(tmp_tests_x[N][:,dim], tmp_tests_y[N],label='test')\n",
    "plt.scatter(tmp_tests_x[N][:,dim], tmp_preds_y[N],label='pred')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(success, 'results/sync.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP-LLS - rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_lls_self/'\n",
    "kernel = 'rbf'\n",
    "n_ts = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end 2 of 2\n",
      "3.8994598468144734 minutes. all fold complete\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "jobs = []\n",
    "for fold in range(K):\n",
    "    for ts in range(n_ts):\n",
    "        jobs.append('python scripts/process_gp_lls_self.py {0} {1} {2}'.format(ts, fold, kernel))\n",
    "\n",
    "print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "sleep(1)\n",
    "n_splits = len(jobs)//64+1\n",
    "for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "    print('start',b_id+1,'of',n_splits)\n",
    "    print('length of batch=',len(batch))\n",
    "    os.system(' | '.join(batch))\n",
    "    clear_output(wait=True)\n",
    "    print('end',b_id+1,'of',n_splits)\n",
    "print((time()-init)/60, 'minutes. all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean_rmse 26.62314973399963\n",
      "Fold 0 individual_rmse 31.554347353983545\n",
      "Fold 1 mean_rmse 21.17898094374728\n",
      "Fold 1 individual_rmse 24.935386502936648\n",
      "Fold 2 mean_rmse 23.79904641242879\n",
      "Fold 2 individual_rmse 26.545866162249574\n",
      "Overall RMSE (individual) 27.82165431991629\n",
      "Overall RMSE (mean of folds) 23.867059030058567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9    5\n",
       "8    5\n",
       "6    4\n",
       "3    4\n",
       "7    3\n",
       "5    2\n",
       "4    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/raw_gp_lls_self/'+kernel+'/'\n",
    "name = 'lls_rbf'\n",
    "master_df[name] = None\n",
    "preds = []\n",
    "tests = []\n",
    "mean_rmse_per_fold = []\n",
    "success = []\n",
    "n_fold_rmse = []\n",
    "for fold in folds:\n",
    "    hyp = []\n",
    "    fold_rmse = []\n",
    "    tmp_preds_y = []\n",
    "    tmp_models = []\n",
    "    tmp_tests_y = []\n",
    "    tmp_tests_x = []\n",
    "    tmp_train_Xy = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        try:\n",
    "            tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            hyp.append(tmp['best_hyperpara']['N'])\n",
    "            preds.append(tmp['pred_y'].squeeze())\n",
    "            tests.append(tmp['test_y'].squeeze())\n",
    "            tmp_models.append(tmp['best_model'])\n",
    "            tmp_train_Xy.append(tmp['train_Xy'])\n",
    "            tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "            tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "            tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "            success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "        except:\n",
    "            pass\n",
    "    print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "    mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "    print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual check (Misc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 0\n",
    "dim = 1\n",
    "plt.plot()\n",
    "plt.scatter(tmp_train_Xy[N][0][:,dim], tmp_train_Xy[N][1],label='train')\n",
    "plt.scatter(tmp_tests_x[N][:,dim], tmp_tests_y[N],label='test')\n",
    "plt.scatter(tmp_tests_x[N][:,dim], tmp_preds_y[N],label='pred')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP-LLS-matern-gp-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'results/raw_gp_lls_matern_gp_extras/'\n",
    "# n_ts = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import differential_evolution\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels \\\n",
    "#     import ConstantKernel as C, Matern\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from gp_extras.kernels import LocalLengthScalesKernel\n",
    "\n",
    "# def de_optimizer(obj_func, initial_theta, bounds):\n",
    "#     res = differential_evolution(lambda x: obj_func(x, eval_gradient=False),\n",
    "#                                  bounds, maxiter=20, disp=False, polish=False)\n",
    "#     return res.x, obj_func(res.x, eval_gradient=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if works\n",
    "# !python scripts/process_gp_lls_gp_extras.py 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init = time()\n",
    "# jobs = []\n",
    "# for fold in range(K):\n",
    "#     for ts in range(n_ts):\n",
    "#         jobs.append('python scripts/process_gp_lls_gp_extras.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "# print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "# sleep(1)\n",
    "# n_splits = len(jobs)//64+1\n",
    "# for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "#     print('start',b_id+1,'of',n_splits)\n",
    "#     print('length of batch=',len(batch))\n",
    "#     os.system(' | '.join(batch))\n",
    "#     clear_output(wait=True)\n",
    "#     print('end',b_id+1,'of',n_splits)\n",
    "# print((time()-init)/60, 'minutes. all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'results/raw_gp_lls_matern_gp_extras/'\n",
    "# name = 'gp_extra_matern'\n",
    "# master_df[name] = None\n",
    "# preds = []\n",
    "# tests = []\n",
    "# mean_rmse_per_fold = []\n",
    "# success = []\n",
    "# n_fold_rmse = []\n",
    "# for fold in folds:\n",
    "#     hyp = []\n",
    "#     fold_rmse = []\n",
    "#     tmp_preds_y = []\n",
    "#     tmp_models = []\n",
    "#     tmp_tests_y = []\n",
    "#     tmp_tests_x = []\n",
    "#     tmp_train_Xy = []\n",
    "#     for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "#         try:\n",
    "#             tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "#             hyp.append(tmp['best_hyperpara']['N'])\n",
    "#             preds.append(tmp['pred_y'].squeeze())\n",
    "#             tests.append(tmp['test_y'].squeeze())\n",
    "#             tmp_models.append(tmp['best_model'])\n",
    "#             tmp_train_Xy.append(tmp['train_Xy'])\n",
    "#             tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "#             tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "#             tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "#             success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "#             fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "#             master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "#         except:\n",
    "#             pass\n",
    "#     print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "#     mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "#     print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "# print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "# print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "# pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_kriging/'\n",
    "n_ts = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if works\n",
    "# !python scripts/process_kriging.py 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init = time()\n",
    "# jobs = []\n",
    "# for fold in range(K):\n",
    "#     for ts in range(n_ts):\n",
    "#         jobs.append('python scripts/process_kriging.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "# print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "# sleep(1)\n",
    "# n_splits = len(jobs)//64+1\n",
    "# for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "#     print('start',b_id+1,'of',n_splits)\n",
    "#     print('length of batch=',len(batch))\n",
    "#     os.system(' | '.join(batch))\n",
    "#     clear_output(wait=True)\n",
    "#     print('end',b_id+1,'of',n_splits)\n",
    "# print((time()-init)/60, 'minutes. all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean_rmse 23.75316884410807\n",
      "Fold 0 individual_rmse 26.699839384773693\n",
      "Fold 1 mean_rmse 19.649797782390547\n",
      "Fold 1 individual_rmse 22.766864313809513\n",
      "Fold 2 mean_rmse 23.047641448882217\n",
      "Fold 2 individual_rmse 24.967948866013174\n",
      "Overall RMSE (individual) 24.863695115783937\n",
      "Overall RMSE (mean of folds) 22.150202691793613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9    6\n",
       "8    5\n",
       "7    3\n",
       "6    3\n",
       "5    3\n",
       "4    3\n",
       "3    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/raw_kriging/'\n",
    "name = 'kriging'\n",
    "master_df[name] = None\n",
    "preds = []\n",
    "tests = []\n",
    "mean_rmse_per_fold = []\n",
    "success = []\n",
    "n_fold_rmse = []\n",
    "for fold in folds:\n",
    "    hyp = []\n",
    "    fold_rmse = []\n",
    "    tmp_preds_y = []\n",
    "    tmp_models = []\n",
    "    tmp_tests_y = []\n",
    "    tmp_tests_x = []\n",
    "    tmp_train_Xy = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        try:\n",
    "            tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            hyp.append(tmp['best_hyperpara']['nlags'])\n",
    "            preds.append(tmp['pred_y'].squeeze())\n",
    "            tests.append(tmp['test_y'].squeeze())\n",
    "            tmp_models.append(tmp['best_model'])\n",
    "            tmp_train_Xy.append(tmp['train_Xy'])\n",
    "            tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "            tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "            tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "            success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "        except:\n",
    "            pass\n",
    "    print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "    mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "    print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_rbf/'\n",
    "n_ts = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if works\n",
    "# !python scripts/process_gp_rbf.py 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init = time()\n",
    "# jobs = []\n",
    "# for fold in range(K):\n",
    "#     for ts in range(n_ts):\n",
    "#         jobs.append('python scripts/process_gp_rbf.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "# print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "# sleep(1)\n",
    "# n_splits = len(jobs)//64+1\n",
    "# for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "#     print('start',b_id+1,'of',n_splits)\n",
    "#     print('length of batch=',len(batch))\n",
    "#     os.system(' | '.join(batch))\n",
    "#     clear_output(wait=True)\n",
    "#     print('end',b_id+1,'of',n_splits)\n",
    "# print((time()-init)/60, 'minutes. all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean_rmse 23.76587720231541\n",
      "Fold 0 individual_rmse 26.610777278549186\n",
      "Fold 1 mean_rmse 18.763100664774672\n",
      "Fold 1 individual_rmse 21.57029630698414\n",
      "Fold 2 mean_rmse 23.061756002838482\n",
      "Fold 2 individual_rmse 24.955738292569148\n",
      "Overall RMSE (individual) 24.469028204833727\n",
      "Overall RMSE (mean of folds) 21.863577956642853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0    15\n",
       "1.0       4\n",
       "0.1       3\n",
       "10.0      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/raw_gp_rbf/'\n",
    "name = 'stat_gp_rbf'\n",
    "master_df[name] = None\n",
    "preds = []\n",
    "tests = []\n",
    "mean_rmse_per_fold = []\n",
    "success = []\n",
    "n_fold_rmse = []\n",
    "for fold in folds:\n",
    "    hyp = []\n",
    "    fold_rmse = []\n",
    "    tmp_preds_y = []\n",
    "    tmp_models = []\n",
    "    tmp_tests_y = []\n",
    "    tmp_tests_x = []\n",
    "    tmp_train_Xy = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        try:\n",
    "            tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            hyp.append(tmp['best_hyperpara']['ls_init'])\n",
    "            preds.append(tmp['pred_y'].squeeze())\n",
    "            tests.append(tmp['test_y'].squeeze())\n",
    "            tmp_models.append(tmp['best_model'])\n",
    "            tmp_train_Xy.append(tmp['train_Xy'])\n",
    "            tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "            tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "            tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "            success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "        except:\n",
    "            pass\n",
    "    print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "    mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "    print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold GP - Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/raw_gp_matern/'\n",
    "n_ts = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if works\n",
    "# !python scripts/process_gp_matern.py 0 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init = time()\n",
    "# jobs = []\n",
    "# for fold in range(K):\n",
    "#     for ts in range(n_ts):\n",
    "#         jobs.append('python scripts/process_gp_matern.py {0} {1}'.format(ts, fold))\n",
    "\n",
    "# print('starting',len(jobs),'jobs on',psutil.cpu_count(),'CPUs')\n",
    "# sleep(1)\n",
    "# n_splits = len(jobs)//64+1\n",
    "# for b_id, batch in enumerate(np.array_split(jobs, n_splits)):\n",
    "#     print('start',b_id+1,'of',n_splits)\n",
    "#     print('length of batch=',len(batch))\n",
    "#     os.system(' | '.join(batch))\n",
    "#     clear_output(wait=True)\n",
    "#     print('end',b_id+1,'of',n_splits)\n",
    "# print((time()-init)/60, 'minutes. all fold complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 mean_rmse 23.042371974442414\n",
      "Fold 0 individual_rmse 26.20930684232478\n",
      "Fold 1 mean_rmse 19.049127576989353\n",
      "Fold 1 individual_rmse 21.716335880678145\n",
      "Fold 2 mean_rmse 22.634774057374443\n",
      "Fold 2 individual_rmse 24.555288494230574\n",
      "Overall RMSE (individual) 24.2314479019342\n",
      "Overall RMSE (mean of folds) 21.575424536268738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0    12\n",
       "0.1       5\n",
       "10.0      4\n",
       "1.0       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/raw_gp_matern/'\n",
    "name = 'stat_gp_matern'\n",
    "master_df[name] = None\n",
    "preds = []\n",
    "tests = []\n",
    "mean_rmse_per_fold = []\n",
    "success = []\n",
    "n_fold_rmse = []\n",
    "for fold in folds:\n",
    "    hyp = []\n",
    "    fold_rmse = []\n",
    "    tmp_preds_y = []\n",
    "    tmp_models = []\n",
    "    tmp_tests_y = []\n",
    "    tmp_tests_x = []\n",
    "    tmp_train_Xy = []\n",
    "    for ts_n, ts in enumerate(df.index.unique()[:n_ts]):\n",
    "        try:\n",
    "            tmp = pd.read_pickle(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            hyp.append(tmp['best_hyperpara']['ls_init'])\n",
    "            preds.append(tmp['pred_y'].squeeze())\n",
    "            tests.append(tmp['test_y'].squeeze())\n",
    "            tmp_models.append(tmp['best_model'])\n",
    "            tmp_train_Xy.append(tmp['train_Xy'])\n",
    "            tmp_tests_x.append(tmp['test_Xy'][0].squeeze())\n",
    "            tmp_preds_y.append(tmp['pred_y'].squeeze())\n",
    "            tmp_tests_y.append(tmp['test_y'].squeeze())\n",
    "            success.append(path+'ts_'+str(ts)+'_fold_'+str(fold))\n",
    "            fold_rmse.append(mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False))\n",
    "            master_df.loc[(str(ts_n), str(ts), str(fold)),name] = mean_squared_error(tmp_tests_y[-1], tmp_preds_y[-1], squared=False)\n",
    "        except:\n",
    "            pass\n",
    "    print('Fold',fold,'mean_rmse',np.mean(fold_rmse))\n",
    "    mean_rmse_per_fold.append(np.mean(fold_rmse))\n",
    "    print(\"Fold\",fold,'individual_rmse',mean_squared_error(np.array(tmp_tests_y).flatten(), np.array(tmp_preds_y).flatten(), squared=False))\n",
    "print(\"Overall RMSE (individual)\", mean_squared_error(np.array(tests).flatten(), np.array(preds).flatten(), squared=False))\n",
    "print(\"Overall RMSE (mean of folds)\", np.mean(mean_rmse_per_fold))\n",
    "pd.Series(hyp).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_pruned = master_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lls_matern</th>\n",
       "      <th>lls_matern_model</th>\n",
       "      <th>lls_rbf</th>\n",
       "      <th>kriging</th>\n",
       "      <th>stat_gp_rbf</th>\n",
       "      <th>stat_gp_matern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>2014-05-01 19:00:00</th>\n",
       "      <th>0</th>\n",
       "      <td>79.0784</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>52.5627</td>\n",
       "      <td>50.4421</td>\n",
       "      <td>53.322</td>\n",
       "      <td>51.8759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>2014-05-01 18:00:00</th>\n",
       "      <th>2</th>\n",
       "      <td>69.6368</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>40.7253</td>\n",
       "      <td>33.8793</td>\n",
       "      <td>29.9512</td>\n",
       "      <td>30.1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>2014-05-02 01:00:00</th>\n",
       "      <th>1</th>\n",
       "      <td>55.1097</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>54.2332</td>\n",
       "      <td>54.3333</td>\n",
       "      <td>54.3487</td>\n",
       "      <td>54.3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>2014-05-01 12:00:00</th>\n",
       "      <th>2</th>\n",
       "      <td>55.0207</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>25.6862</td>\n",
       "      <td>25.5653</td>\n",
       "      <td>25.7281</td>\n",
       "      <td>25.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>2014-05-01 21:00:00</th>\n",
       "      <th>0</th>\n",
       "      <td>52.8115</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>51.2618</td>\n",
       "      <td>50.704</td>\n",
       "      <td>51.275</td>\n",
       "      <td>51.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>2014-05-02 00:00:00</th>\n",
       "      <th>1</th>\n",
       "      <td>9.51039</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>9.46285</td>\n",
       "      <td>10.4595</td>\n",
       "      <td>10.4084</td>\n",
       "      <td>10.4027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">22</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2014-05-02 03:00:00</th>\n",
       "      <th>2</th>\n",
       "      <td>7.47419</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>7.35378</td>\n",
       "      <td>7.96888</td>\n",
       "      <td>7.37382</td>\n",
       "      <td>7.37944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.64781</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>6.37928</td>\n",
       "      <td>6.22665</td>\n",
       "      <td>7.60941</td>\n",
       "      <td>7.69981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>2014-05-02 02:00:00</th>\n",
       "      <th>0</th>\n",
       "      <td>6.48147</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>6.483</td>\n",
       "      <td>6.56755</td>\n",
       "      <td>7.61375</td>\n",
       "      <td>7.73343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>2014-05-02 03:00:00</th>\n",
       "      <th>1</th>\n",
       "      <td>5.65938</td>\n",
       "      <td>&lt;NSGPy.NumPy.latent_lengthscale_model.latent_l...</td>\n",
       "      <td>5.69599</td>\n",
       "      <td>5.88574</td>\n",
       "      <td>5.69804</td>\n",
       "      <td>5.70548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         lls_matern  \\\n",
       "15 2014-05-01 19:00:00 0    79.0784   \n",
       "14 2014-05-01 18:00:00 2    69.6368   \n",
       "20 2014-05-02 01:00:00 1    55.1097   \n",
       "8  2014-05-01 12:00:00 2    55.0207   \n",
       "16 2014-05-01 21:00:00 0    52.8115   \n",
       "...                             ...   \n",
       "19 2014-05-02 00:00:00 1    9.51039   \n",
       "22 2014-05-02 03:00:00 2    7.47419   \n",
       "                       0    6.64781   \n",
       "21 2014-05-02 02:00:00 0    6.48147   \n",
       "22 2014-05-02 03:00:00 1    5.65938   \n",
       "\n",
       "                                                           lls_matern_model  \\\n",
       "15 2014-05-01 19:00:00 0  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "14 2014-05-01 18:00:00 2  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "20 2014-05-02 01:00:00 1  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "8  2014-05-01 12:00:00 2  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "16 2014-05-01 21:00:00 0  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "...                                                                     ...   \n",
       "19 2014-05-02 00:00:00 1  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "22 2014-05-02 03:00:00 2  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "                       0  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "21 2014-05-02 02:00:00 0  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "22 2014-05-02 03:00:00 1  <NSGPy.NumPy.latent_lengthscale_model.latent_l...   \n",
       "\n",
       "                          lls_rbf  kriging stat_gp_rbf stat_gp_matern  \n",
       "15 2014-05-01 19:00:00 0  52.5627  50.4421      53.322        51.8759  \n",
       "14 2014-05-01 18:00:00 2  40.7253  33.8793     29.9512        30.1241  \n",
       "20 2014-05-02 01:00:00 1  54.2332  54.3333     54.3487        54.3487  \n",
       "8  2014-05-01 12:00:00 2  25.6862  25.5653     25.7281        25.7433  \n",
       "16 2014-05-01 21:00:00 0  51.2618   50.704      51.275        51.3797  \n",
       "...                           ...      ...         ...            ...  \n",
       "19 2014-05-02 00:00:00 1  9.46285  10.4595     10.4084        10.4027  \n",
       "22 2014-05-02 03:00:00 2  7.35378  7.96888     7.37382        7.37944  \n",
       "                       0  6.37928  6.22665     7.60941        7.69981  \n",
       "21 2014-05-02 02:00:00 0    6.483  6.56755     7.61375        7.73343  \n",
       "22 2014-05-02 03:00:00 1  5.69599  5.88574     5.69804        5.70548  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "lets_see = master_df_pruned.sort_values(['lls_matern'], ascending=False)\n",
    "lets_see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lls_matern        24.557542\n",
       "lls_rbf           23.867059\n",
       "kriging           22.150203\n",
       "stat_gp_rbf       21.863578\n",
       "stat_gp_matern    21.575425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lets_see.mean() # Mean rmse across all time-stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.02066127823238 4\r\n",
      "test_y [181, 229, 143, 186, 157, 143, 142, 156, 186, 162, 172, 197]\r\n",
      "pred_y [143, 145, 189, 169, 141, 166, 158, 195, 188, 188, 157, 49]\r\n",
      "len [[-1.39184396 -1.29140207]\r\n",
      " [-1.19119598  0.5007697 ]\r\n",
      " [ 1.43330296 -0.55748694]\r\n",
      " [-0.88923435  1.151472  ]\r\n",
      " [ 0.0062672  -0.05878688]\r\n",
      " [ 0.25259967 -0.37332047]\r\n",
      " [ 3.76480064  0.77028676]\r\n",
      " [-0.01187286 -0.60414155]\r\n",
      " [-1.20405076 -0.91865453]\r\n",
      " [ 0.05952119 -0.55104791]\r\n",
      " [-1.55257419 -0.29087002]\r\n",
      " [-0.51477134 -2.43892423]]\r\n",
      "{'likelihood (mll)': 80.73014300057771, 'GP_variance (sigma_f)': array([197.52765919]), 'GP_noise_level (sigma_n)': array([3218.15460038]), 'L_GP_variance (sigma_f_bar)': array([1., 1.]), 'L_GP_lengthscale (sigma_l_bar)': array([6.1331107e+03, 1.0000000e-03]), 'L_GP_noise_level (sigma_n_bar)': array([0.001, 0.001]), 'N_lengthscales (l_bar)': array([[4.35047371e+02, 3.44417343e+01],\r\n",
      "       [1.09573844e+03, 2.16156027e+01],\r\n",
      "       [5.73703423e+02, 4.77920427e+02],\r\n",
      "       [5.08901549e-02, 6.96836387e+02]])}\r\n"
     ]
    }
   ],
   "source": [
    "!python scripts/process_gp_lls_self.py 8 2 matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'likelihood (mll)': 74.21934970730186,\n",
       " 'GP_variance (sigma_f)': array([184.56712923]),\n",
       " 'GP_noise_level (sigma_n)': array([168.4601668]),\n",
       " 'L_GP_variance (sigma_f_bar)': array([1., 1.]),\n",
       " 'L_GP_lengthscale (sigma_l_bar)': array([2.88541540e-02, 4.02276847e+02]),\n",
       " 'L_GP_noise_level (sigma_n_bar)': array([0.001, 0.001]),\n",
       " 'N_lengthscales (l_bar)': array([[55.47325506, 96.74195398],\n",
       "        [ 0.98651587, 25.76852447],\n",
       "        [48.12095533, 19.95852996]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = pd.read_pickle('scripts/scratch/test_model')\n",
    "original_params = test_model.params\n",
    "test_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.29747066390199,\n",
       " array([[10.        ,  1.        ],\n",
       "        [ 1.        , 25.76852447],\n",
       "        [48.12095533, 19.95852996]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.l_bar[0,0] = 10\n",
    "test_model.l_bar[0,1] = 1\n",
    "test_model.l_bar[1,0] = 1\n",
    "mean_squared_error([148, 99, 143, 67, 101, 130, 182, 82, 174, 130, 71, 103],\n",
    "                   test_model.predict(test_model.X_star, False), squared=False),\\\n",
    "test_model.l_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6k4WgBqgL+Y9j9KIJPQp/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GP_Extra_LLS_self_implement.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
